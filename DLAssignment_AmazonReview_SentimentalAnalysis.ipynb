{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e42ee6",
   "metadata": {},
   "source": [
    "# Assignment project 7 : \n",
    "# Amazon reviews analysis. This dataset consists of a few million Amazon customer reviews (input text) and star ratings (output labels) for learning how to train fastText for sentiment analysis. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69bb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import bz2\n",
    "import re\n",
    "\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bda2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fucntion to load the text and labels from train and test set\n",
    "\n",
    "def get_labels_texts(file):\n",
    "    labels= []\n",
    "    texts= []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        x= line.decode(\"utf-8\")\n",
    "        labels.append(int(x[9]) - 1)\n",
    "        texts.append(x[10:].strip())\n",
    "    return np.array(labels), texts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5851ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to get the labels and texts\n",
    "\n",
    "train_labels, train_texts= get_labels_texts('train.ft.txt.bz2')\n",
    "test_labels, test_texts= get_labels_texts('test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa87592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]    # just seeing what is in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945e3a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e1ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11799b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DVD Player crapped out after one year: I also began having the incorrect disc problems that I've read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that's a sign on bad quality. I'm giving up JVC after this as well. I'm sticking to Sony or giving another brand a shot.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56c8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As said in the question we have millions of review so to make it little easier will t ake only 1000 reviews \n",
    "\n",
    "train_labels= train_labels[0:500]\n",
    "train_texts= train_texts[0:500]\n",
    "\n",
    "test_labels= test_labels[0:500]\n",
    "test_texts= test_texts[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a600663b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(train_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5c2cf",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8500e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alphanum= re.compile(r'[\\W]')\n",
    "non_ascii= re.compile(r'[^a-z0-1\\s]')\n",
    "\n",
    "def normalize_texts(texts):\n",
    "    normalized_texts = []\n",
    "    for text in texts: \n",
    "        lower= text.lower()\n",
    "        no_punctuation= non_alphanum.sub(r' ', lower)\n",
    "        no_non_ascii= non_ascii.sub(r'', no_punctuation )\n",
    "        normalized_texts.append(no_non_ascii)\n",
    "    return normalized_texts\n",
    "\n",
    "\n",
    "  # lets use this function for train and test set\n",
    "train_texts= normalize_texts(train_texts)\n",
    "test_texts= normalize_texts(test_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb25fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuning even for the non gamer  this sound track was beautiful  it paints the senery in your mind so well i would recomend it even to people who hate vid  game music  i have played the game chrono cross but out of all of the games i have ever played it has the best music  it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras  it would impress anyone who cares to listen    '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b22317c",
   "metadata": {},
   "source": [
    "# Now we will start with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71510028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will first split the train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(train_texts, train_labels, train_size=0.80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbe128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization is the process of dividing the sentence into a series of tokens. \n",
    "# Simply put, whenever there is a space in a sentence, the process of tokenization adds a comma between them so the sentence will be broken down into tokens.\n",
    "# Each word gets a unique integer value so that my model can process the text for further analysis.\n",
    "\n",
    "MAX_FEATURES = 12000\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_texts = tokenizer.texts_to_sequences(x_train)\n",
    "test_texts = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2b7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The max() function returns the item with the highest value in an iterable.\n",
    "# Here, the variable 'MAX_LENGTH' returns the longest text in the training dataset.\n",
    "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
    "\n",
    "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
    "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)\n",
    "\n",
    "# 'pad_sequences' is used to ensure that all sequences in a list have the same length.\n",
    "# By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
    "# Simply put, padding is the method of converting the integer array of variable length into fixed-length when the length is shorter than the max_length. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3548ef",
   "metadata": {},
   "source": [
    "# Convolutional Neural Net Model\n",
    "I'm just using fairly simple models here. This CNN has an embedding with a dimension of 64, 3 convolutional layers with the first two having batch normalization and max pooling and the last with global max pooling. The results are then passed to a dense layer and then the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf01dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
    "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(5)(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    \n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b9d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 195)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 195, 64)           768000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 193, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 193, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 64, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 60, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 64)             20544     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 828,553\n",
      "Trainable params: 828,297\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a512ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 107ms/step - loss: 0.8960 - binary_accuracy: 0.5425\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 1s 116ms/step - loss: 0.4177 - binary_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257a042ef40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  now evrything is ready, lets fit the model \n",
    "\n",
    "model.fit(train_texts, y_train, batch_size= 128, epochs= 3)    #just giving 2,3 epochs to save time.. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7426f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6897 - binary_accuracy: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6896663904190063, 0.8974999785423279]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets evealuate train set \n",
    "model.evaluate(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "779188a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6933 - binary_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932892799377441, 0.5199999809265137]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  we then evaluate the test set \n",
    "model.evaluate(test_texts, y_test)                  # here x_test is test_texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94150b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred= model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da758d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.52\n",
      "F1 score: 0.5636\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: {:0.4}'.format(accuracy_score(y_test, 1 * (y_pred > 0.5))))\n",
    "\n",
    "print('F1 score: {:0.4}'.format(f1_score(y_test, 1 * (y_pred > 0.5))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd8a5d",
   "metadata": {},
   "source": [
    "# Trying RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3388717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model():\n",
    "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
    "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
    "    \n",
    "    x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "    x= layers.LSTM(128)(x)\n",
    "    x= layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    rnn_model = models.Model(inputs=sequences, outputs=predictions)\n",
    "   \n",
    "    \n",
    "    rnn_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "        \n",
    "rnn_model = build_rnn_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7327d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 195)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 195, 64)           768000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 193, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 193, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 64, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 60, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 64)             20544     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 828,553\n",
      "Trainable params: 828,297\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "041a7b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.2256 - binary_accuracy: 0.9800\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.1429 - binary_accuracy: 0.9975\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.0775 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257a5197e50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(train_texts, y_train, batch_size= 128, epochs= 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9897fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6902 - binary_accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6902111172676086, 0.5350000262260437]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.evaluate(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c8ccf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6923 - binary_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6923419833183289, 0.550000011920929]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.evaluate(test_texts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b91f8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5044147 ],\n",
       "       [0.50553006],\n",
       "       [0.5010786 ],\n",
       "       [0.50521123],\n",
       "       [0.50689816]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1= rnn_model.predict(test_texts)\n",
    "y_pred1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3b57989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step\n",
      "Accuracy score: 0.55\n",
      "F1 score: 0.7097\n"
     ]
    }
   ],
   "source": [
    "preds = rnn_model.predict(test_texts)\n",
    "print('Accuracy score: {:0.4}'.format(accuracy_score(y_test, 1 * (y_pred1 > 0.5))))\n",
    "print('F1 score: {:0.4}'.format(f1_score(y_test, 1 * (y_pred1 > 0.5))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e00582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9193f4ab",
   "metadata": {},
   "source": [
    "# Conclusion: F1 score for RNN model was better than CNN model.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba872a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDL1",
   "language": "python",
   "name": "venvdl1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
